# Fast R-CNN
CNN fine tuning, boundnig box regression, classification을 모두 하나의 네트워크에서 학습시키는 " **end-to-end** 기법을 제시한 모델 "
## 핵심 아이디어
> - SPP NET 의 한계점
>   1. 여러 단계의 학습 (CNN, SVM, Bounding box regression)
>   2. Fully connected layer 밖에 학습을 시키지 못함.\
> - 이러한 한계점을 극복하고자한 모델이 Fast R-CNN

## 알고리즘
> 1. 전체이미지를 pretrain 된 CNN에 통과 , feature map 추출
> 2. Selective search를 통해 얻은 각각의 ROI에 대해 ROI Pooling 수행 , 고정된 크기의 feature vector 추출
> 3. feature vector는 fc layer를 통과, **2개의 branch로 나뉘게 된다.**
> 4. (1) 하나의 branch는 softmax를 통과, 해당 ROI가 어떤 물체인지 **classification**. (더이상 svm은 사용하지 않는다.)\
> (2) bounding box regression을 통해 selective search로 찾은 **박스위치 조정**.

> - step별로 쪼개어 학습을 진행하지 않고 **end-to-end**로 엮였다는 것이 가장 큰 포인트
> - 학습속도, 인퍼런스속도, 정확도 모두 향상

## Roi Pooling
> ### ROI pooling layer
> ![image](https://user-images.githubusercontent.com/70633080/103257623-4934f080-49d5-11eb-9d65-167ccdcd4b79.png)
> 1. 입력이미지에서 feature map 추출.
> 2. 추출된 feature map에 selective search를 적용하여 ROI선별
> 3. 선별된 ROI를 모두 지정된 H*W size (ex. 7*7)로 만들어줌
> 4. max pooling 수행을 통해 항상 H*W size의 feature map이 만들어진다.
> 5. feature map을 flatten시켜 feature vector 추출.
> 6. 2개의 FC Layer를 거침.
> 7. 2개를 거쳐 생성된 feature들은 softmax, bbox regression에 각각 사용
>![image](https://user-images.githubusercontent.com/70633080/103200144-f2291000-492f-11eb-9e12-ac2d3d39f2b9.png)
> - **RoI Pooling은 간단히 말해서 크기가 다른 Feature Map의 Region마다 Stride를 다르게 Max Pooling을 진행하여 결과값을 맞추는 방법이다.**
> - Roi pooling은 spatial pyramid poooling 의 pyramid level1의 경우와 동일하다.
> - input image size 와 feature map size 가 다를 경우\
>   : 비율을 구해 ROI를 조절한 후 ROI Pooling을 진행.
> ### single bin
> - SPP-NET 방식\
>   : 하나의 객체를 3개의 resolution으로 학습하는 것과 같다.
>   하나의 객체를 지나치게 학습하여 overfitting이 발생할 수 있다.\
>![image](https://user-images.githubusercontent.com/70633080/103258105-37544d00-49d7-11eb-8734-7b5e07fcef46.png)
> - SPP-NET에서 사용했던 1*1, 2*2, 4*4 3가지 spatial bin을 이용하는 것 보다, 7*7 spatial bin을 사용해 overfitting 문제를 피할 수 있다.
> ### Truncated SVD 
> : Fast RCNN에서는 마지막 FC Layer에 **SVM이 아닌 Truncated SVD기법**이 사용되었다.
> - 한번의 CNN과정과 2000개의 ROI영역에 대한 FC Layer 수행으로 FC Layer에서 소요되는 시간이 많아진다.
> - 무수히 많은 FC Layer의 연산들은 이 기법으로 compression되어 parameter수를 줄이고 test시간도 줄일 수 있다.
> ### Fine tunning
> - Fast RCNN은 svm을 따로 classifier로 쓰지않고 기존 CNN의 classifier(soft max)를 그대로 사용하여 동시에 cnn,softmax,bbox를 학습한다.
> - 이를 one single stage라고 한다.

## Multi Task Loss
> : RCNN, SPP-NET은 BBox와 classification을 따로 학습시켰다. 그러나 Fast RCNN은 동시에 학습 시키도록 만들었다. \
>   또한 , 하나의 loss function을 만들어 multi-task를 수행하도록 하였다.
> - train 
>     - 앞에서 얻은 feature vector로 classification과 bounding box regression을 적용하여 각각의 loss를 얻는다.
>     - 이를 back propagation하여 전체모델을 학습시킨다.
> ![image](https://user-images.githubusercontent.com/70633080/103258736-b185d100-49d9-11eb-815e-cf0bdb073f15.png)
> ### Multi Task Loss
> : classification loss 와 bounding box regression을 적절히 엮어주는 것
> #### 수식
> - 전체 loss는 classification loss 와 bbox 즉, localization loss로 구성된다
> ![image](https://user-images.githubusercontent.com/70633080/103200675-54364500-4931-11eb-8421-d448af6cc508.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103258774-e85be700-49d9-11eb-80f6-a2f19d80fd13.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103200792-a5463900-4931-11eb-8e8d-00ee6d62e370.png)\
> -**입력 P** : sotf max를 통해 얻은 K+1( 물체 k + 배경 1)개의 확률 값\
> -**u** : 해당 ROI의 ground truth label 값.
>
> #### BB Regression
> : k+1개의 class에 대한 x,y,h,w값을 조정하는 t_k를 return.\
> ex) 사람일 경우 box를 n만큼, 고양이일 경우 m 만큼 조절해라.\
> ![image](https://user-images.githubusercontent.com/70633080/103201092-5c42b480-4932-11eb-85c2-fd9e01ed6e4e.png)
> #### loss function
> - loss 앞부분 (classification)\
> ![image](https://user-images.githubusercontent.com/70633080/103201111-6ebcee00-4932-11eb-8014-800dcddb6c7c.png)\
>     - p와 u를 가지고 classification loss를 구한다. (log loss사용)
> - loss 뒷부분(localization)\
> BB Regression을 통해 얻는 loss이다.\
> ![image](https://user-images.githubusercontent.com/70633080/103201168-9613bb00-4932-11eb-996d-dfb846f15894.png)\
>     - 인자로 t와 v가 필요하다.
>     - 입력 : 정답라벨에 해당하는 BBR예측값, ground truth 조절값
>     - t_u : ground truth label에 해당하는 값
>     - v : ground truth bounding box의 조절 값
>     - x,y,w,h 각각에 대해 예측값과 라벨 값의 차이를 계산 한 후 smoothL1이라는 함수를 통과시킨 합을 계산한다.
> #### smooth L1
> ![image](https://user-images.githubusercontent.com/70633080/103201756-053ddf00-4934-11eb-82c1-c91ddb7c73e9.png)
> - 예측값 - 라벨값 <1\
> : 0.5x*2 로 L2 Distance를 계산한다.
> - 예측값 - 라벨값 <=1\
> : L1 Distance를 계산한다.
> - 라벨값과 지나치게 차이가 많이나는 outlier 예측값들이 발생, 이들을 L2로 계산할 경우 gradient exploding문제가 발생한다. 따라서 다음 함수를 추가한 것이다.

## Backpropogation through ROI Pooling layer
> - loss function을 구했으니 network 학습이 필요하다.
> - 네트워크를 어디까지 학습 시킬 것인가?
>     - SPP NET : feature map을 추출하는 CNN은 제외하고 SPP이후의 FC만 fine-tune하였다.\
>       이는 이미지로부터 특징을 뽑는 **가장 중요한 CNN**이 학습될 수 없어 성능향상에 제약이 있다는 주장이 있었다.
>     - 과연 ROI Pooling layer 이전까지 역전파를 전달할 수 있는가!
> ### 수식
> ![image](https://user-images.githubusercontent.com/70633080/103202306-631ef680-4935-11eb-9ee9-76655a139592.png)
> - x_i : CNN을 통해 추출된 feature map에서 하나의 feature 값 (실수)
> - 전체 Loss에 대해 이 x_i에 대한 편미분 값을 구하면 그 값이 x_i에 대한 loss 값이 되며 역전파 알고리즘을 수행할 수 있게 된다.
> 
> - feature map에서 ROI를 찾고 ROI Pooling을 적용하기 위해 h*w size의 grid로 나눈다.
>     - grid 를 sub-window라고 부른다. 
>     - j : 몇번째 sub-window인지를 나타내는 인덱스.
> - y_rj : ROI Pooling을 통과해 최종적으로 얻어진 output값. (하나의 실수)\
> ![image](https://user-images.githubusercontent.com/70633080/103202510-fa844980-4935-11eb-8d8b-d62719265535.png)
> - x_i가 최종 prediction 값에 영향을 주기 위해선 x_i가 속하는 모든 ROI의 sub-window에서 해당 x_i가 최댓값이어야 한다.
> - i*(r,j) : ROI와 sub-window index j 가 주어졌을때, 최대 feature 값의 index. = ROI Pooling을 통과하는 index값. 
> - RoI Pooling을 통과한 이후 값(y_rj)에 대한 Loss는 이미 전체 Loss에 대한 yrj의 편미분 값으로 이미 계산이 되어 있다.
> - 따라서, 이를 중첩시키기만 하면 xi에 대한 loss를 구할 수 있는 것이다.\
> " 앞서 구한 multitask loss를 RoI Pooling layer를 통과하여 CNN 단까지 fine-tuning 할 수 있는 것 "

## 정리
> - fine tunning 하는 깊이를 조절하며 성능 비교
> ![image](https://user-images.githubusercontent.com/70633080/103204378-957f2280-493a-11eb-9974-5c30ba9cd0af.png)
> - CNN까지 fine tunning을 하는 것이 성능향상에 도움이 됨을 알 수 있다.
> - CNN의 단을 깊이 학습시킬 수록 성능이 향상
> - test시간변화는 거의 없다.
> ### 한계점
> 여전히 region proposal을 selective search로 수행하고 이는 CPU연산만 가능하다는 한계점이 존재한다.

## 참고자료
> <https://89douner.tistory.com/90>
> <https://nuggy875.tistory.com/33?category=860935>
>
