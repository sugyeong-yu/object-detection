# Faster R-CNN
Deep Network를 사용해 Region Proposal을 진행하는 **RPN(Region proposal networks)**를 소개한다.\
![image](https://user-images.githubusercontent.com/70633080/103259626-8ac99980-49dd-11eb-8837-4053dc070d08.png)\
**즉, Fast R-CNN에서 selective search가 하던 일을 Faster R-CNN에서 RPN이 하는 것**
- RPN\
**RPN을 통해 GPU를 통한 ROI계산이 가능해졌다.**\
RPN의 output들은 Fast R-CNN과 동일하게 ROI Pooling , Classification, Bbox regression을 진행하게 된다.
- input :  image의 Feature Map
- output : Object proposal들의 Sample
- R-CNN, Fast R-CNN, Faster R-CNN의 구조
![image](https://user-images.githubusercontent.com/70633080/103259764-1cd1a200-49de-11eb-8f5c-03373675e31d.png)
## RPN (Region Proposal Network)
> - RPN은 selective search가 2000개의 roi를 계산하는데 비해 800개 정도의 roi를 계산하면서도 높은 정확도를 보인다.\
> ![image](https://user-images.githubusercontent.com/70633080/103259872-9073af00-49de-11eb-895e-67a90fd0fdc2.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103336435-8378bd80-4abb-11eb-8d13-6beda97effc1.png)
> 1. 입력으로 들어온 feature map을 h * w * c 크기로 정한다.
> 2. Feature Map에 3 * 3 convolution을 256 또는 512 채널 수 만큼 수행한다. 
>     1. padding을 1로 설정해 h * w 가 보존될 수 있도록 한다.
>     2. k개의 Anchor box를 통해 영역을 정한다.
> 3. feqture map을 통해 classification과 BBox regression 예측값을 계산한다.
>     1. **FC layer대신 1 * 1 conv의 fc layer 특징을 가지는 Fully convolution network를 사용한다.**
>     2. 이때, Classification layer는 물체의 유무를 판단하는 이진분류로 class수는 2이다.
> 4. classification 수행을 위해 1 * 1 conv를 2(물체인지,아닌지) * 9(앵커개수) 채널수 만큼 수행해준다.
>     1. h * w * 18 size의 feature map을 얻는다.
>     2. h * w 는 feature map 상의 좌표를, 18은 해당 좌표를 앵커로 삼아 k개의 앵커박스들이 object 인지아닌지 예측값을 담고 있다.
>     3. 이 값들을 적절히 reshape 해준 뒤 softmax를 통해 해당 앵커가 오브젝트일 확률을 얻는다.
> 5. bounding box regression 예측값을 얻기 위해 1 * 1 conv를 4 * 9 채널수만큼 수행한다.
>     1. 4개의 좌표가 반환된다. (x,y,w,h)
> 6. 얻은 값들을 통해 ROI를 계산한다. 
>     1. classification을 통해 얻은 물체일 확률 값들을 정렬한 후 높은 순으로 k개의 앵커만 추려낸다.
>     2. k개의 앵커들에 각각 bounding box regression을 적용한다. 
>     3. 그 후 Non-Maximum-Suppression을 적용해 ROI를 구한다.
> 7. 최종적으로 찾은 ROI를 첫번째 feature map에 project한 후 ROI pooling등 다음 단계를 진행한다.
> ### Anchor Targeting
> input image의 size를 800 * 800이라고 가정.
> - CNN을 거쳐 추출된 Feature Map에 **sliding window 방법으로 각 중심 좌표를 중심으로 k=9개의 anchor box를 만든다.**
> - Anchor box는 3개의 scale(8,16,32)과 3개의 ratio(0.5,1,2)를 통해 9개가 만들어 진다.
> ![image](https://user-images.githubusercontent.com/70633080/103260098-adf54880-49df-11eb-9971-1a347f05401b.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103260131-ded57d80-49df-11eb-91e1-3c3edd67c512.png)
> - 800 * 800에서 생성된 50 * 50 feature map추출
> - subsampling ratio = 16 = (800 / 50)을 기준으로 sliding window 방식적용
>     - 16 * 16 안의 중심픽셀을 중심으로 anchor box를 9개씩 적용하여 50 * 50 * 9 =22500개의 anchor box를 만든다.
> ![image](https://user-images.githubusercontent.com/70633080/103260257-5c998900-49e0-11eb-815f-1327b5a49b02.png)\
> 위 그림은 800 * 800 image 기준 400 * 400 에서의 9개의 anchor box들이다.
> - 22500개의 anchor box를 기준으로 물체가 있는지 없는지를 학습한다.
> - image와 그에 대한 ground truth box가 들어왔을때 각 anchor마다 물체를 감싸는지 배경을 감싸는지 labeling이 필요하다.
> #### GT Label
> > 각 22500개의 anchor들과 ground truth box의 IOU를 계산한다.
> > IOU = 교집합 / 합집합
> > - IOU > 0.7 이면 positive(1)
> > - IOU < 0.3 이면 Negative(0)
> > - 나머지 경우는 -1
> > 이때, Positive label이 많지 않을 수 있어 ground truth box마다 IOU가 가장 높은 anchor를 1개 뽑아 이를 positive로 labeling한다.
>
> ### Prediction
## Loss Function
> 
