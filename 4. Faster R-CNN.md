# Faster R-CNN
Deep Network를 사용해 Region Proposal을 진행하는 **RPN(Region proposal networks)**를 소개한다.\
![image](https://user-images.githubusercontent.com/70633080/103259626-8ac99980-49dd-11eb-8837-4053dc070d08.png)\
**즉, Fast R-CNN에서 selective search가 하던 일을 Faster R-CNN에서 RPN이 하는 것**
- RPN\
**RPN을 통해 GPU를 통한 ROI계산이 가능해졌다.**\
RPN의 output들은 Fast R-CNN과 동일하게 ROI Pooling , Classification, Bbox regression을 진행하게 된다.
- input :  image의 Feature Map
- output : Object proposal들의 Sample
- R-CNN, Fast R-CNN, Faster R-CNN의 구조
![image](https://user-images.githubusercontent.com/70633080/103259764-1cd1a200-49de-11eb-8f5c-03373675e31d.png)
## RPN (Region Proposal Network)
> - RPN은 selective search가 2000개의 roi를 계산하는데 비해 800개 정도의 roi를 계산하면서도 높은 정확도를 보인다.\
> ![image](https://user-images.githubusercontent.com/70633080/103259872-9073af00-49de-11eb-895e-67a90fd0fdc2.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103336435-8378bd80-4abb-11eb-8d13-6beda97effc1.png)
> 1. 입력으로 들어온 feature map을 h * w * c 크기로 정한다.
> 2. Feature Map에 3 * 3 convolution을 256 또는 512 채널 수 만큼 수행한다. 
>     1. padding을 1로 설정해 h * w 가 보존될 수 있도록 한다.
>     2. k개의 Anchor box를 통해 영역을 정한다.
> 3. feqture map을 통해 classification과 BBox regression 예측값을 계산한다.
>     1. **FC layer대신 1 * 1 conv의 fc layer 특징을 가지는 Fully convolution network를 사용한다.**
>     2. 이때, Classification layer는 물체의 유무를 판단하는 이진분류로 class수는 2이다.
> 4. classification 수행을 위해 1 * 1 conv를 2(물체인지,아닌지) * 9(앵커개수) 채널수 만큼 수행해준다.
>     1. h * w * 18 size의 feature map을 얻는다.
>     2. h * w 는 feature map 상의 좌표를, 18은 해당 좌표를 앵커로 삼아 k개의 앵커박스들이 object 인지아닌지 예측값을 담고 있다.
>     3. 이 값들을 적절히 reshape 해준 뒤 softmax를 통해 해당 앵커가 오브젝트일 확률을 얻는다.
> 5. bounding box regression 예측값을 얻기 위해 1 * 1 conv를 4 * 9 채널수만큼 수행한다.
>     1. 4개의 좌표가 반환된다. (x,y,w,h)
> 6. 얻은 값들을 통해 ROI를 계산한다. 
>     1. classification을 통해 얻은 물체일 확률 값들을 정렬한 후 높은 순으로 k개의 앵커만 추려낸다.
>     2. k개의 앵커들에 각각 bounding box regression을 적용한다. 
>     3. 그 후 Non-Maximum-Suppression을 적용해 ROI를 구한다.
> 7. 최종적으로 찾은 ROI를 첫번째 feature map에 project한 후 ROI pooling등 다음 단계를 진행한다.
> ### Anchor Targeting
> input image의 size를 800 * 800이라고 가정.
> - CNN을 거쳐 추출된 Feature Map에 **sliding window 방법으로 각 중심 좌표를 중심으로 k=9개의 anchor box를 만든다.**
> - Anchor box는 3개의 scale(8,16,32)과 3개의 ratio(0.5,1,2)를 통해 9개가 만들어 진다.
> ![image](https://user-images.githubusercontent.com/70633080/103260098-adf54880-49df-11eb-9971-1a347f05401b.png)\
> ![image](https://user-images.githubusercontent.com/70633080/103260131-ded57d80-49df-11eb-91e1-3c3edd67c512.png)
> - 800 * 800에서 생성된 50 * 50 feature map추출
> - subsampling ratio = 16 = (800 / 50)을 기준으로 sliding window 방식적용
>     - 16 * 16 안의 중심픽셀을 중심으로 anchor box를 9개씩 적용하여 50 * 50 * 9 =22500개의 anchor box를 만든다.
> ![image](https://user-images.githubusercontent.com/70633080/103260257-5c998900-49e0-11eb-815f-1327b5a49b02.png)\
> 위 그림은 800 * 800 image 기준 400 * 400 에서의 9개의 anchor box들이다.
> - 22500개의 anchor box를 기준으로 물체가 있는지 없는지를 학습한다.
> - image와 그에 대한 ground truth box가 들어왔을때 각 anchor마다 물체를 감싸는지 배경을 감싸는지 labeling이 필요하다.
> #### GT Label
> > 각 22500개의 anchor들과 ground truth box의 IOU를 계산한다.
> > IOU = 교집합 / 합집합
> > - IOU > 0.7 이면 positive(1)
> > - IOU < 0.3 이면 Negative(0)
> > - 나머지 경우는 -1
> > 이때, Positive label이 많지 않을 수 있어 ground truth box마다 IOU가 가장 높은 anchor를 1개 뽑아 이를 positive로 labeling한다.
>
> ### Prediction
> - image 크기가 800 * 800 이라고 가정했을 때,
> 1. 50 * 50 * 512 크기의 feature map을 conv layer를 한번 거치고 
> 2. 1 * 1 conv인 bbox regression layer (50 * 50 * 512 -> 50 * 50 * (anchor 9 * class 4) 와 classification layer ( 50 * 50 * (anchor 9 * class 2 )를 통해 
> 3. 물체 영역과 물체 유무의 prediction을 완료한다.\
> ![image](https://user-images.githubusercontent.com/70633080/103343358-40c0e080-4acf-11eb-97e3-279b3b0f3988.png)
> - 따라서 output은 anchor수에 맞춰 (22500,2) 그리고 (22500,4)이 된다.
> - prediction된 두 값은 NMS를 거쳐 특정개수의 ROIㄹ sampling된 후, Fast-R-CNN에 사용된다.
## Loss Function
> RPN을 학습시키기 위한 Loss에 대해서 살펴본다.\
> ![image](https://user-images.githubusercontent.com/70633080/103339449-c25f4100-4ac4-11eb-8ff0-66fa4e7f5697.png)
> - classification 과 bounding box regression 두 task에서 얻은 로스의 멀티태스크형태이다.
>     - i : 하나의 앵커
>     - pi : 해당 앵커가 오브젝트일 확률
>     - ti : bounding box regression을 통해 얻은 박스 조정 값 벡터
>     - pi* , ti* : ground truth label
>     - Nreg : dodzj rotn ( ex) 256 * 9 ) 
>     - 람다 : classification loss와 regression loss 사이 가중치를 조절해주는 부분. ( 논문에서는 10으로 설정되어 사실상 두 로스는 동일한 가중치가 매겨진다)
> - classification loss 는 log loss를 사용한다.
> - regression 의 경우 Fast R-CNN에서 소개된 smoothL1 함수를 사용한다.\
> ![image](https://user-images.githubusercontent.com/70633080/103339677-59c49400-4ac5-11eb-864d-5d389cc30cb4.png)

## NMS(Non-Maximum Suppression) & ROI Sampling
> Prediction 된 BOX들에 NMS를 거치고 ROI Sampling을 통해 최종 ROI를 결정하게 된다.
> ### NMS
> Detection 에서 주로 중복되는 bounding box를 제거하기 위해서 쓰인다.\
> ![image](https://user-images.githubusercontent.com/70633080/103343895-7b774880-4ad0-11eb-99ce-18fbafca0961.png)\
> 많은 수의 anchor box끼리 겹치는 부분이 많기 때문에 한 물체에 여러 bounding box가 생기게 된다. 따라서 NMS로 중복 bounding box를 제거한다.
> 1. Prediction box들 중 ROI Score로 정렬 한 뒤
> 2. 높은 ROI Score을 가진 box와 overlapping된 다른 box들을 지워 나가는 식으로 반복한다.
> - box overlapping을 방지하면서 ROI가 높은 box들만 남도록 하는 방식이다.
> - overlapping에 대한 threshold는 주로 0.6에서 0.9 정도를 사용한다.
> ### ROI Sampling
> 보통 training 시, NMS를 거치게되면 2000개의 ROI가 남는다.\
> 이 중 , Positive와 Negative의 비율이 1:1이 되도록 ROI를 sampling한다.\
> 256개를 sampling한다고 가정했을때, 약 128개의 positive, 128개의 negative anchor이 sampling된다.\
> 만약 positive anchor이 128개가 안된다면 zero padding이나 IOU값이 가장 높은 box를 선택한다.
## Traning
> 모델전체를 한번에 학습시키는 것은 매우 어려운 작업이다. 따라서, 저자들은 4단계에 걸쳐 모델을 번갈아가며 학습을 시키는 **Alternating Traning** 기법을 사용한다.
> 1. ImageNet pretrained model을 불러온 뒤 RPN을 학습시킨다.
> 2. 학습시킨 RPN에서 기본 CNN을 제외한 region proposal layer만 가져온다. 
>     1. 이를 활용해 Fast R-CNN을 학습시킨다. 
>     2. 이때, 처음 feature map을 추출하는 CNN까지 fine tune시킨다.
> 3. 앞서 학습시킨 Fast R-CNN과 RPN을 불러온 뒤, 다른 weight들은 고정하고 RPN에해당하는 layer들만 fine tune시킨다.
>     1. 여기서부터 RPN과 Fast R-CNN이 convolution weight를 공유하게 된다.
> 4. 마지막으로 공유하는 CNN과 RPN은 고정시킨 채, Fast R-CNN에 해당하는 Layer만 fine tune 시킨다.
