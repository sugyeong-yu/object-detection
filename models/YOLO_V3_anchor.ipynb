{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backborn \n",
    "YOLO V3는 백본으로 DarkNet-53을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "# 입력이미지 랜덤생성\n",
    "input_image=torch.randn(1,3,416,416)\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBL(in_c,out_c,kernel_size,stride,padding):\n",
    "    dbl_block=nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size=kernel_size,padding=padding,stride=stride),\n",
    "                            nn.BatchNorm2d(out_c),\n",
    "                            nn.LeakyReLU())\n",
    "    return dbl_block\n",
    "\n",
    "class Res_unit(nn.Module):\n",
    "    def __init__(self,in_c):\n",
    "        super(Res_unit,self).__init__()\n",
    "        \n",
    "        reduce_c=int(in_c/2)\n",
    "        self.layer1=DBL(in_c,reduce_c,1,1,0)\n",
    "        self.layer2=DBL(reduce_c,in_c,3,1,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res_connection= x\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=out+res_connection\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Res_unit(3).forward(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet53(nn.Module):\n",
    "    def __init__(self,block):\n",
    "        super(Darknet53,self).__init__()\n",
    "        \n",
    "        self.conv1=DBL(3,32,3,1,1)\n",
    "        self.conv2=DBL(32,64,3,2,1)\n",
    "        \n",
    "        self.res_block1=self.num_block(block,64,num=1)\n",
    "        self.conv3=DBL(64,128,3,2,1)\n",
    "        \n",
    "        self.res_block2=self.num_block(block,128,2)\n",
    "        self.conv4=DBL(128,256,3,2,1)\n",
    "        \n",
    "        self.res_block3=self.num_block(block,256,8)\n",
    "        self.conv5=DBL(256,512,3,2,1) # 3*3 conv하면 마진1 > 패딩으로 채워줌\n",
    "        \n",
    "        self.res_block4=self.num_block(block,512,8)\n",
    "        self.conv6=DBL(512,1024,3,2,1)\n",
    "        \n",
    "        self.res_block5=self.num_block(block,1024,4)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.res_block1(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.res_block2(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.res_block3(x)\n",
    "        feature3=x\n",
    "        x=self.conv5(x)\n",
    "        x=self.res_block4(x)\n",
    "        feature2=x\n",
    "        x=self.conv6(x)\n",
    "        x=self.res_block5(x)\n",
    "        feature1=x\n",
    "        \n",
    "        return feature1,feature2,feature3\n",
    "    def num_block(self,block,in_c,num):\n",
    "        layers=[]\n",
    "        for i in range(num):\n",
    "            layers.append(Res_unit(in_c))\n",
    "        return nn.Sequential(*layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darknet53(Res_unit).forward(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  yolov3 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo_v3,self).__init__()\n",
    "        self.class_num=80\n",
    "        self.img_size=416\n",
    "        anchor = {'grid52': [(10, 13), (16, 30), (33, 23)],\n",
    "                   'grid26': [(30, 61), (62, 45), (59, 119)],\n",
    "                   'grid13': [(116, 90), (156, 198), (373, 326)]}\n",
    "        \n",
    "        \n",
    "        self.darknet53=Darknet53(Res_unit)\n",
    "        \n",
    "        self.conv_set1=self.conv_set(1024,512)\n",
    "        self.conv_final1=self.conv_final(512,255)\n",
    "        self.anchor_box1=YoloDetection(anchor['grid13'],self.img_size,self.class_num)\n",
    "        \n",
    "        self.conv_layer1=DBL(512,256,1,1,0)\n",
    "        self.upsampling1=nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        \n",
    "        self.conv_set2=self.conv_set(768,256) # 왜 나누기 3???????????\n",
    "        self.conv_final2=self.conv_final(256,255)\n",
    "        self.anchor_box2=YoloDetection(anchor['grid26'],self.img_size,self.class_num)\n",
    "        \n",
    "        self.conv_layer2=DBL(256,128,1,1,0)\n",
    "        self.upsampling2=nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.conv_set3=self.conv_set(384,128)\n",
    "        self.conv_final3=self.conv_final(128,255)\n",
    "        self.anchor_box3=YoloDetection(anchor['grid52'],self.img_size,self.class_num)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        print(\"darknet53 \")\n",
    "        res5,res4,res3=self.darknet53(x)\n",
    "        \n",
    "        print(\"=========================================\")\n",
    "        print(\"yolov3\")\n",
    "#         print(\"res3: \",res3.shape) # res 1이후\n",
    "#         print(\"res4: \",res4.shape) # res 3이후\n",
    "#         print(\"res5: \",res5.shape)# 마지막\n",
    "\n",
    "        # 1번째 feature 뽑기\n",
    "        out1=self.conv_set1(res5)\n",
    "        first=self.conv_final1(out1)\n",
    "        \n",
    "        anchor13=self.anchor_box1(first) #[1,507,85]\n",
    "        \n",
    "        # 2번째 feature\n",
    "        out2=self.conv_layer1(out1)\n",
    "        out2=self.upsampling1(out2)\n",
    "        out2=torch.cat((out2,res4),dim=1)\n",
    "#         print(\"concate1_result:\",out2.shape)\n",
    "        out2=self.conv_set2(out2)\n",
    "        second=self.conv_final2(out2)\n",
    "        \n",
    "        anchor26=self.anchor_box2(second) #[1, 2028, 85]\n",
    "\n",
    "        \n",
    "        #3번째 feature\n",
    "        out3=self.conv_layer2(out2)\n",
    "        out3=self.upsampling2(out3)\n",
    "        out3=torch.cat((out3,res3),dim=1)\n",
    "#         print(\"concate2_result:\", out3.shape)\n",
    "        out3=self.conv_set3(out3)\n",
    "        thrid=self.conv_final3(out3)\n",
    "        \n",
    "        anchor52=self.anchor_box3(thrid) #[1, 8112, 85]\n",
    "        \n",
    "        # feature 크기출력\n",
    "        print(\">>>>> featuremap extract <<<<<\")\n",
    "        print(\"first_feature:\",first.shape)\n",
    "        print(\"second_feature:\", second.shape)            \n",
    "        print(\"thrid_feature:\",thrid.shape)\n",
    "        \n",
    "        # anchor box합치기\n",
    "        print(\">>>>> anchor box prediction <<<<<\")\n",
    "        pred_BBOX=[anchor13,anchor26,anchor52]\n",
    "        pred_BBOX=torch.cat(pred_BBOX,1) # 인덱스1번째 차원으로 합치기. shape: [1,10647,85]\n",
    "        \n",
    "        \n",
    "    def conv_set(self,in_c,out_c):\n",
    "        increase_c=out_c*2\n",
    "        result=nn.Sequential(DBL(in_c,out_c,1,1,0),\n",
    "                             DBL(out_c,increase_c,3,1,1),\n",
    "                             DBL(increase_c,out_c,1,1,0),\n",
    "                             DBL(out_c,increase_c,3,1,1),\n",
    "                             DBL(increase_c,out_c,1,1,0))\n",
    "        return result\n",
    "    \n",
    "    def conv_final(self,in_c,out_c):\n",
    "        result=nn.Sequential(DBL(in_c,in_c*2,3,1,1),\n",
    "                            nn.Conv2d(in_c*2,out_c,1,1,0))\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darknet53 layer size\n",
      "=========================================\n",
      "torch.Size([1, 3, 13, 13, 85])\n",
      "torch.Size([1, 3, 26, 26, 85])\n",
      "torch.Size([1, 3, 52, 52, 85])\n",
      "first_feature: torch.Size([1, 255, 13, 13])\n",
      "second_feature: torch.Size([1, 255, 26, 26])\n",
      "thrid_feature: torch.Size([1, 255, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "Yolo_v3().forward(x=input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDetection(nn.Module):\n",
    "    def __init__(self,anchor,img_size,classnum):\n",
    "        super(YoloDetection,self).__init__()\n",
    "        self.anchor=anchor\n",
    "        self.img_size=img_size\n",
    "        self.numclass=classnum\n",
    "        self.mse_loss=nn.MSELoss()\n",
    "        self.bce_loss=nn.BCELoss()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size=x.size(0)\n",
    "        num_anchor=len(self.anchor)\n",
    "        grid_size=x.size(2) # 13-> 26-> 52\n",
    "        \n",
    "        pred=(x.view(batch_size,num_anchor,5+self.numclass,grid_size,grid_size)\n",
    "             .permute(0,1,3,4,2).contiguous())\n",
    "        print(pred.shape) # batch, anchor,img,img,5+class\n",
    "        \n",
    "        tx=torch.sigmoid(pred[...,0]) #  시작은 그냥 특징맵의 x좌표로 변화량 계산 -> 학습을 통해 변화\n",
    "        ty=torch.sigmoid(pred[...,1]) # 모두 0~1 사이값 즉, 변화량\n",
    "        w= pred[...,2]\n",
    "        h=pred[...,3]\n",
    "        pred_conf=torch.sigmoid(pred[...,4]) # object confidence\n",
    "        pred_cls=torch.sigmoid(pred[...,5:]) # class prediction\n",
    "        \n",
    "        stride=self.img_size/grid_size  # 416/13 = 32\n",
    "        left_x=torch.arange(grid_size,dtype=torch.float).repeat(grid_size,1).view([1,1,grid_size,grid_size])\n",
    "        left_y=torch.arange(grid_size,dtype=torch.float).repeat(grid_size,1).t().view([1,1,grid_size,grid_size]) # y니까 전치해주기 t()\n",
    "        \n",
    "        # grid 나눈거에 맞춰서 anchor크기도 맞춰주기 ex) 4 -> 2 \n",
    "        grid_anchor=torch.as_tensor([(anchor_w/stride, anchor_h/stride) for anchor_w,anchor_h in self.anchor],dtype=float)\n",
    "        \n",
    "        anchor_w=grid_anchor[:,0].view((1,num_anchor,1,1))\n",
    "        anchor_h=grid_anchor[:,1].view((1,num_anchor,1,1)) # 왜이런 형태로?\n",
    "        \n",
    "        # 상대좌표 구하기 (grid상 좌표) 좌상단 + 변화량\n",
    "        pred_bbox=torch.zeros_like(pred[...,:4]) # x,y,w,h 크기의 예측박스 \n",
    "        pred_bbox[...,0]=left_x + tx # 좌상단좌표 + 변화량\n",
    "        pred_bbox[...,1]=left_y + ty\n",
    "        pred_bbox[...,2]=torch.exp(w)*anchor_w\n",
    "        pred_bbox[...,3]=torch.exp(h)*anchor_h\n",
    "        \n",
    "        #print(pred_bbox.shape) # (1,3,13,13,4)\n",
    "        \n",
    "        # x,y,w,h 와 conf, cls 합쳐주기\n",
    "        # 절대좌표구하기\n",
    "        pred=(pred_bbox.view(batch_size,-1,4)*stride, #(1,507,4)\n",
    "             pred_conf.view(batch_size,-1,1), # (1,507,1)\n",
    "             pred_cls.view(batch_size,-1,self.numclass)) # (1,507,80)\n",
    "        output=torch.cat(pred,-1) # 마지막차원을 기준으로 합친다. (1,507,85)\n",
    "        \n",
    "#         if target is None :\n",
    "#             print(\"target is none\")\n",
    "#             return output, 0\n",
    "        \n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
